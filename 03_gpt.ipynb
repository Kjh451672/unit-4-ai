{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2 Large Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 1.56Git/s]                                                     \n",
      "Fetching encoder.json: 1.05Mit [00:00, 1.90Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 4.88Git/s]                                                   \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [06:30, 1.28Mit/s]                                  \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 2.66Git/s]                                               \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 3.08Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 3.77Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "#gpt2.download_gpt2(model_name = '124M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "session = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(session, model_name='124M', reuse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The moon came hurdling towards the earth ƒ\n",
      "\n",
      "-- and at that point the earth moved a little closer to the sun.\n",
      "\n",
      "Then a pang of anger was thrown at him.\n",
      "\n",
      "He said:\n",
      "\n",
      "\"You are taking advantage of the irreparable loss of my father.\n",
      "\n",
      "Let me tell you, my brethren, that I do not like to be your father.\n",
      "\n",
      "I know that my father no longer loves you. You have become my father.\"\n",
      "\n",
      "--and for the rest of the day\n",
      "\n",
      "When the heavens could not be higher, they were more open.\n",
      "\n",
      "Then a great spring came up from under the earth in the sky.\n",
      "\n",
      "And a great whirlpool was formed in its little spot.\n",
      "\n",
      "This was a great whirlpool, and it had a tremendous extent.\n",
      "\n",
      "And the great whirlpool was so turbulent that it was trembling.\n",
      "\n",
      "And the other world was filled with a great whirlwind.\n",
      "\n",
      "One of the sea's stars was slowly clearing away its debris.\n",
      "\n",
      "And there were a great number of them.\n",
      "\n",
      "And the great whirlpool was so intense that the earth was writhing.\n",
      "\n",
      "And the earth was full of many birds that were trembling.\n",
      "\n",
      "And the rain came down on the earth.\n",
      "\n",
      "And the earth heaved with a great roar.\n",
      "\n",
      "And the earth was filled with a great number of ghosts that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of ghosts that were sitting in the earth.\n",
      "\n",
      "So the earth grew heavier, and the earth was filled with a multitude of creatures.\n",
      "\n",
      "But the earth was filled with a great number of creatures that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of ghosts that were sitting in the earth.\n",
      "\n",
      "The earth was full of a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of ghosts that were sitting in the earth.\n",
      "\n",
      "The earth was filled with a great number of ghosts that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of ghosts that were sitting in the earth.\n",
      "\n",
      "The earth was full of a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of ghosts that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of ghosts that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of ghosts that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of ghosts that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of ghosts that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of ghosts that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of ghosts that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of ghosts that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "--and then the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "And the earth was filled with a great number of birds that were sitting in the earth.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(\n",
    "    session,\n",
    "    model_name = '124M',\n",
    "    prefix = 'The moon came hurdling towards the earth ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakespeare GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session2 = gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732547125.065028 4042090 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 338025 tokens\n",
      "Training...\n",
      "[1 | 18.72] loss=4.25 avg=4.25\n",
      "[2 | 38.23] loss=3.72 avg=3.98\n",
      "[3 | 56.63] loss=3.96 avg=3.98\n",
      "[4 | 74.36] loss=3.75 avg=3.92\n",
      "[5 | 91.70] loss=3.74 avg=3.88\n",
      "[6 | 109.33] loss=3.53 avg=3.82\n",
      "[7 | 126.13] loss=3.92 avg=3.84\n",
      "[8 | 142.91] loss=3.73 avg=3.82\n",
      "[9 | 159.41] loss=3.49 avg=3.78\n",
      "[10 | 175.81] loss=3.93 avg=3.80\n",
      "[11 | 192.57] loss=3.52 avg=3.77\n",
      "[12 | 209.00] loss=3.56 avg=3.75\n",
      "[13 | 226.78] loss=3.82 avg=3.76\n",
      "[14 | 243.45] loss=3.46 avg=3.74\n",
      "[15 | 260.19] loss=3.73 avg=3.74\n",
      "[16 | 276.58] loss=3.64 avg=3.73\n",
      "[17 | 293.14] loss=3.55 avg=3.72\n",
      "[18 | 309.96] loss=3.28 avg=3.69\n",
      "[19 | 326.58] loss=3.56 avg=3.68\n",
      "[20 | 343.07] loss=3.53 avg=3.68\n",
      "[21 | 359.43] loss=3.54 avg=3.67\n",
      "[22 | 375.93] loss=3.39 avg=3.65\n",
      "[23 | 391.94] loss=3.33 avg=3.64\n",
      "[24 | 408.09] loss=3.06 avg=3.61\n",
      "[25 | 424.10] loss=3.31 avg=3.60\n",
      "[26 | 440.32] loss=3.47 avg=3.59\n",
      "[27 | 457.79] loss=3.56 avg=3.59\n",
      "[28 | 476.02] loss=3.41 avg=3.58\n",
      "[29 | 494.11] loss=3.20 avg=3.57\n",
      "[30 | 511.81] loss=3.42 avg=3.56\n",
      "[31 | 529.63] loss=3.51 avg=3.56\n",
      "[32 | 546.94] loss=3.48 avg=3.56\n",
      "[33 | 564.64] loss=3.23 avg=3.55\n",
      "[34 | 583.21] loss=3.35 avg=3.54\n",
      "[35 | 601.54] loss=3.34 avg=3.53\n",
      "[36 | 619.15] loss=3.45 avg=3.53\n",
      "[37 | 636.62] loss=3.13 avg=3.52\n",
      "[38 | 654.84] loss=3.67 avg=3.52\n",
      "[39 | 672.15] loss=3.18 avg=3.51\n",
      "[40 | 689.46] loss=3.31 avg=3.51\n",
      "[41 | 708.13] loss=3.43 avg=3.50\n",
      "[42 | 726.57] loss=3.46 avg=3.50\n",
      "[43 | 745.17] loss=3.27 avg=3.50\n",
      "[44 | 763.90] loss=3.21 avg=3.49\n",
      "[45 | 782.08] loss=3.49 avg=3.49\n",
      "[46 | 799.98] loss=3.37 avg=3.48\n",
      "[47 | 817.42] loss=3.16 avg=3.48\n",
      "[48 | 834.51] loss=3.50 avg=3.48\n",
      "[49 | 852.04] loss=3.37 avg=3.47\n",
      "[50 | 869.82] loss=3.07 avg=3.46\n",
      "[51 | 887.37] loss=3.06 avg=3.45\n",
      "[52 | 905.27] loss=3.41 avg=3.45\n",
      "[53 | 922.76] loss=3.35 avg=3.45\n",
      "[54 | 940.69] loss=3.17 avg=3.44\n",
      "[55 | 957.95] loss=3.45 avg=3.44\n",
      "[56 | 975.67] loss=3.10 avg=3.44\n",
      "[57 | 994.71] loss=3.45 avg=3.44\n",
      "[58 | 1012.70] loss=3.22 avg=3.43\n",
      "[59 | 1030.81] loss=3.29 avg=3.43\n",
      "[60 | 1048.93] loss=3.40 avg=3.43\n",
      "[61 | 1066.84] loss=3.29 avg=3.42\n",
      "[62 | 1083.87] loss=3.36 avg=3.42\n",
      "[63 | 1101.08] loss=3.24 avg=3.42\n",
      "[64 | 1117.85] loss=3.31 avg=3.42\n",
      "[65 | 1135.17] loss=3.09 avg=3.41\n",
      "[66 | 1152.21] loss=3.60 avg=3.41\n",
      "[67 | 1169.43] loss=3.22 avg=3.41\n",
      "[68 | 1186.62] loss=3.21 avg=3.41\n",
      "[69 | 1203.01] loss=3.27 avg=3.40\n",
      "[70 | 1220.19] loss=3.26 avg=3.40\n",
      "[71 | 1237.09] loss=3.04 avg=3.39\n",
      "[72 | 1254.94] loss=3.09 avg=3.39\n",
      "[73 | 1271.95] loss=3.30 avg=3.39\n",
      "[74 | 1289.66] loss=3.23 avg=3.38\n",
      "[75 | 1307.24] loss=3.46 avg=3.38\n",
      "[76 | 1324.54] loss=3.05 avg=3.38\n",
      "[77 | 1341.83] loss=3.35 avg=3.38\n",
      "[78 | 1358.81] loss=3.27 avg=3.38\n",
      "[79 | 1376.15] loss=3.09 avg=3.37\n",
      "[80 | 1393.96] loss=3.19 avg=3.37\n",
      "[81 | 1411.54] loss=3.18 avg=3.36\n",
      "[82 | 1428.53] loss=3.40 avg=3.36\n",
      "[83 | 1446.14] loss=3.19 avg=3.36\n",
      "[84 | 1463.90] loss=3.25 avg=3.36\n",
      "[85 | 1482.34] loss=3.27 avg=3.36\n",
      "[86 | 1499.75] loss=3.38 avg=3.36\n",
      "[87 | 1517.97] loss=3.30 avg=3.36\n",
      "[88 | 1536.73] loss=3.37 avg=3.36\n",
      "[89 | 1554.53] loss=3.15 avg=3.35\n",
      "[90 | 1572.83] loss=3.33 avg=3.35\n",
      "[91 | 1591.73] loss=3.37 avg=3.35\n",
      "[92 | 1611.13] loss=2.90 avg=3.35\n",
      "[93 | 1628.53] loss=3.30 avg=3.35\n",
      "[94 | 1647.94] loss=3.09 avg=3.34\n",
      "[95 | 1666.27] loss=3.10 avg=3.34\n",
      "[96 | 1683.92] loss=3.31 avg=3.34\n",
      "[97 | 1701.46] loss=3.13 avg=3.33\n",
      "[98 | 1718.24] loss=3.24 avg=3.33\n",
      "[99 | 1736.73] loss=3.20 avg=3.33\n",
      "[100 | 1756.32] loss=3.11 avg=3.33\n",
      "Saving checkpoint/shakespeare/model-100\n"
     ]
    }
   ],
   "source": [
    "gpt2.finetune(\n",
    "    session2,\n",
    "    'shakespeare.txt',\n",
    "    model_name = '124M',\n",
    "    steps = 100,\n",
    "    run_name = 'shakespeare'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kyle: Fruit Salad, yummy yummy!\n",
      "\n",
      "GARNISH:\n",
      "Ay, sweet wife, yesss!\n",
      "\n",
      "GRUMIO:\n",
      "The fruit is ready, my lord.\n",
      "I'll make a good supper, and then I'll go to bed.\n",
      "\n",
      "GARNISH:\n",
      "Alas, the wine is not ready, and I would not go.\n",
      "\n",
      "GRUMIO:\n",
      "I'll go with my heart to the bell.\n",
      "\n",
      "GRUMIO:\n",
      "You are a tyrant!\n",
      "\n",
      "GLOUCESTER:\n",
      "Well, then, are you a tyrant?\n",
      "\n",
      "GRUMIO:\n",
      "And never be a tyrant!\n",
      "\n",
      "GLOUCESTER:\n",
      "I am a tyrant, that is,\n",
      "But when I go to the door\n",
      "I'll see the tyrant's face before me.\n",
      "\n",
      "GLOUCESTER:\n",
      "O my lord!\n",
      "\n",
      "GRUMIO:\n",
      "O, my lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "O, my lord!\n",
      "\n",
      "GRUMIO:\n",
      "O, my lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "O, my lord!\n",
      "\n",
      "GRUMIO:\n",
      "O, my lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "O, my lord!\n",
      "\n",
      "GRUMIO:\n",
      "I will make supper from the fire.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "Go, go, go!\n",
      "\n",
      "GLOUCESTER:\n",
      "You are a tyrant!\n",
      "\n",
      "GRUMIO:\n",
      "I will not go.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GRUMIO:\n",
      "My lord!\n",
      "\n",
      "GARNISH:\n",
      "How many times have I been a tyrant?\n",
      "\n",
      "GLOUCESTER:\n",
      "I have been a tyrant:\n",
      "I have been a tyrant the whole of my life,\n",
      "All those tyrant years, I have been a tyrant.\n",
      "\n",
      "GLOUCESTER:\n",
      "I have been a tyrant the whole of my life,\n",
      "The whole of my life, the whole of my life,\n",
      "All those tyrant years, I have been a tyrant.\n",
      "\n",
      "GLOUCESTER:\n",
      "I have been a tyrant the whole of my life,\n",
      "The whole of my life, the whole of my life,\n",
      "The whole of my life, the whole of my life,\n",
      "The whole of my life, every tyrant years, I have been a tyrant.\n",
      "\n",
      "GLOUCESTER:\n",
      "I have been a tyrant the whole of my life,\n",
      "The whole of my life, the whole of my life,\n",
      "All those tyrant years, I have been a tyrant.\n",
      "\n",
      "GLOUCESTER:\n",
      "I have been a tyrant the whole of my life,\n",
      "The whole of my life, the whole of my life,\n",
      "The whole of my life, every tyrant years, I have been a tyrant.\n",
      "\n",
      "GLOUCESTER:\n",
      "I have been a tyrant the whole of my life,\n",
      "The whole of my life, the whole of my life,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(\n",
    "    session2,\n",
    "    prefix= 'Kyle: Fruit Salad, yummy yummy!',\n",
    "    run_name = 'shakespeare'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
